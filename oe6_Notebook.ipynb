{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Name:\n",
        "#Section & Year:\n",
        "#Date:\n",
        "#AI-Powered Exploratory Data Analytics (EDA) using Hugging Face API and Gradio in Python:\n",
        "#From Descriptive to Prescriptive Insights\n",
        "\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "from huggingface_hub import InferenceClient\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, accuracy_score, f1_score\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "import warnings\n",
        "import requests\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "#---------- CONFIG --------------------------\n",
        "HF_TOKEN = \"YOUR HUGGING FACE TOKEN\"\n",
        "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
        "\n",
        "#Test if Hugging Face connection is live (supports both text-generation & conversational models)\n",
        "def test_hf_connection(token, model):\n",
        "    try:\n",
        "        client = InferenceClient(model=model, token=token)\n",
        "        # Some models (like Mistral) support only chat/completion, not text_generation\n",
        "        try:\n",
        "            _ = client.text_generation(\"Connection test\", max_new_tokens=5)\n",
        "            return client, \"Hugging Face connection successful (text-generation).\"\n",
        "        except Exception:\n",
        "            # Try conversational fallback\n",
        "            _ = client.chat_completion(messages=[{\"role\": \"user\", \"content\": \"Connection test\"}], max_tokens=5)\n",
        "            return client, \"Hugging Face connection successful (chat model).\"\n",
        "    except requests.exceptions.RequestException:\n",
        "        return None, \"Network connection to Hugging Face failed.\"\n",
        "    except Exception as e:\n",
        "        return None, f\"Hugging Face connection error: {str(e)}\"\n",
        "\n",
        "client, HF_STATUS = test_hf_connection(HF_TOKEN, MODEL_NAME)\n",
        "\n",
        "# Display connection state for logging or Gradio UI\n",
        "print(HF_STATUS)\n",
        "\n",
        "# Visualization defaults\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.rcParams.update({'figure.max_open_warning': 0})\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kmt5gMgPCF_A",
        "outputId": "ba6eed1d-9d93-48b5-896b-ae5d157527d5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Hugging Face connection successful (chat model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- Helpers ----------\n",
        "def fig_to_pil(dpi=150):\n",
        "    buf = BytesIO()\n",
        "    plt.savefig(buf, format=\"png\", bbox_inches='tight', dpi=dpi)\n",
        "    buf.seek(0)\n",
        "    img = Image.open(buf).convert(\"RGB\")\n",
        "    buf.close()\n",
        "    plt.close()\n",
        "    return img\n",
        "\n",
        "\n",
        "def load_file_to_df(file):\n",
        "    \"\"\"\n",
        "    Robust loader that accepts:\n",
        "      - gr.File upload (file-like / temporary path)\n",
        "      - a plain path-like object (str)\n",
        "      - a file-like object\n",
        "    Returns (df, error_message_or_None)\n",
        "    \"\"\"\n",
        "    if file is None:\n",
        "        return None, \"No file provided.\"\n",
        "    try:\n",
        "        # gr.File sometimes gives a SpooledTemporaryFile-like object with .name attribute.\n",
        "        # If file is a dict (old gradio), try the common keys -> but generally gradio passes a file-like.\n",
        "        # Accept strings (path) too.\n",
        "        if isinstance(file, str):\n",
        "            # path\n",
        "            if file.lower().endswith(\".csv\"):\n",
        "                df = pd.read_csv(file)\n",
        "            else:\n",
        "                df = pd.read_excel(file)\n",
        "            return df, None\n",
        "\n",
        "        # If file has attribute 'name' that's a path on disk\n",
        "        name = getattr(file, \"name\", None)\n",
        "        if isinstance(name, str) and name.lower().endswith(\".csv\"):\n",
        "            # some environments (notably local testing) expose a filesystem path\n",
        "            try:\n",
        "                df = pd.read_csv(name)\n",
        "                return df, None\n",
        "            except Exception:\n",
        "                # fallback to reading file object\n",
        "                file.seek(0)\n",
        "                df = pd.read_csv(file)\n",
        "                return df, None\n",
        "        if isinstance(name, str) and name.lower().endswith((\".xls\", \".xlsx\")):\n",
        "            try:\n",
        "                df = pd.read_excel(name)\n",
        "                return df, None\n",
        "            except Exception:\n",
        "                file.seek(0)\n",
        "                df = pd.read_excel(file)\n",
        "                return df, None\n",
        "\n",
        "        # fallback: try reading as CSV first, then Excel\n",
        "        try:\n",
        "            file.seek(0)\n",
        "        except Exception:\n",
        "            pass\n",
        "        try:\n",
        "            df = pd.read_csv(file)\n",
        "            return df, None\n",
        "        except Exception:\n",
        "            try:\n",
        "                if hasattr(file, \"seek\"):\n",
        "                    file.seek(0)\n",
        "                df = pd.read_excel(file)\n",
        "                return df, None\n",
        "            except Exception as e:\n",
        "                return None, f\"Could not parse file as CSV or Excel: {e}\"\n",
        "    except Exception as e:\n",
        "        return None, f\"Error loading file: {e}\""
      ],
      "metadata": {
        "id": "03Yw6nM8E7oz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- Target detection ----------\n",
        "TARGET_KEYWORDS = [\n",
        "    \"target\", \"label\", \"y\", \"price\", \"sales\", \"amount\", \"revenue\", \"score\", \"churn\", \"status\", \"outcome\", \"rating\"\n",
        "]\n",
        "\n",
        "\n",
        "def detect_target_column(df):\n",
        "    cols = list(df.columns)\n",
        "    # 1) keyword matching\n",
        "    for c in cols:\n",
        "        name = c.lower()\n",
        "        for kw in TARGET_KEYWORDS:\n",
        "            # check tokens and underscore variant\n",
        "            if kw in name.split() or kw in name.replace(\"_\", \" \"):\n",
        "                return c, f\"Found keyword '{kw}' in column name.\"\n",
        "    # 2) numeric heuristic\n",
        "    num_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
        "    if num_cols:\n",
        "        scored = []\n",
        "        for c in num_cols:\n",
        "            nunique = int(df[c].nunique(dropna=True))\n",
        "            miss = float(df[c].isna().mean())\n",
        "            var = float(df[c].var() if pd.notna(df[c].var()) else 0.0)\n",
        "            score = (min(1, nunique / max(1, len(df) // 10)) * 0.5) + ((1 - miss) * 0.3) + (min(1, var / (var + 1e-9)) * 0.2)\n",
        "            if nunique / max(1, len(df)) > 0.9:\n",
        "                score *= 0.3\n",
        "            scored.append((c, score, nunique, miss))\n",
        "        scored.sort(key=lambda x: x[1], reverse=True)\n",
        "        if scored:\n",
        "            cand = scored[0][0]\n",
        "            return cand, f\"Numeric candidate selected (score={scored[0][1]:.2f}, unique={scored[0][2]}, missing={scored[0][3]:.2f}).\"\n",
        "    # 3) categorical small-cardinality\n",
        "    cat_cols = df.select_dtypes(include='object').columns.tolist()\n",
        "    for c in cat_cols:\n",
        "        nunique = df[c].nunique(dropna=True)\n",
        "        if 2 <= nunique <= 20:\n",
        "            return c, f\"Categorical candidate with {nunique} classes.\"\n",
        "    return None, \"No obvious target detected. Please choose one.\""
      ],
      "metadata": {
        "id": "-dzPNCdkEz2o"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- LLM interpret helper ----------\n",
        "def llm_interpret_short(title, details):\n",
        "    if not client:\n",
        "        return f\"LLM disabled. {title}: {details}\"\n",
        "    prompt = f\"\"\"You are a data analyst. Given the chart/title: {title} and details: {details}\n",
        "Provide a concise 2-sentence interpretation highlighting trends, anomalies, or predictive hints.\"\"\"\n",
        "    try:\n",
        "        resp = client.chat.completions.create(model=MODEL_NAME,\n",
        "                                             messages=[{\"role\": \"user\", \"content\": prompt}], max_tokens=150)\n",
        "        return resp.choices[0].message[\"content\"].strip()\n",
        "    except Exception as e:\n",
        "        return f\"LLM failed: {e}\"\n",
        "\n",
        "\n",
        "def llm_final_summary(df, task_type, target, brief_visual_interps):\n",
        "    if not client:\n",
        "        return \"LLM disabled.\"\n",
        "    prompt = f\"\"\"\n",
        "You are an experienced data scientist. The dataset columns: {', '.join(df.columns.tolist()[:12])}.\n",
        "Task type: {task_type}. Target: {target}.\n",
        "Visual interpretations:\n",
        "{brief_visual_interps}\n",
        "\n",
        "Produce a concise, structured 4-part analytics report:\n",
        "1) Descriptive\n",
        "2) Diagnostic\n",
        "3) Predictive\n",
        "4) Prescriptive\n",
        "Keep it short and specific.\n",
        "\"\"\"\n",
        "    try:\n",
        "        resp = client.chat.completions.create(model=MODEL_NAME,\n",
        "                                             messages=[{\"role\": \"user\", \"content\": prompt}], max_tokens=400)\n",
        "        return resp.choices[0].message[\"content\"].strip()\n",
        "    except Exception as e:\n",
        "        return f\"LLM failed: {e}\""
      ],
      "metadata": {
        "id": "ibLTSTHvEvfr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- Auto-visual selection ----------\n",
        "def select_visuals_for_dataset(df, target=None):\n",
        "    imgs, interps = [], []\n",
        "    num_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
        "    cat_cols = df.select_dtypes(include='object').columns.tolist()\n",
        "    date_cols = df.select_dtypes(include=[\"datetime64\", \"datetime64[ns]\"]).columns.tolist()\n",
        "\n",
        "    # Target-focused visuals\n",
        "    if target and target in df.columns:\n",
        "        try:\n",
        "            if pd.api.types.is_numeric_dtype(df[target]):\n",
        "                plt.figure(figsize=(5, 3))\n",
        "                sns.histplot(df[target].dropna(), kde=True)\n",
        "                plt.title(f\"Target distribution: {target}\")\n",
        "                imgs.append(fig_to_pil())\n",
        "                interps.append(llm_interpret_short(f\"Target distribution: {target}\", f\"Histogram of {target}\"))\n",
        "                # top correlated numeric predictors\n",
        "                if num_cols:\n",
        "                    corr = df[num_cols + [target]].corr()[target].drop(labels=[target], errors='ignore').abs().sort_values(ascending=False)\n",
        "                    top = corr.head(3).index.tolist()\n",
        "                    for p in top:\n",
        "                        plt.figure(figsize=(5, 4))\n",
        "                        sns.scatterplot(data=df, x=p, y=target)\n",
        "                        plt.title(f\"{target} vs {p}\")\n",
        "                        imgs.append(fig_to_pil())\n",
        "                        interps.append(llm_interpret_short(f\"{target} vs {p}\", f\"Scatter and linear tendency between {p} and {target}.\"))\n",
        "            else:\n",
        "                plt.figure(figsize=(5, 3))\n",
        "                vc = df[target].value_counts().head(10)\n",
        "                sns.barplot(x=vc.values, y=vc.index)\n",
        "                plt.title(f\"Target class distribution: {target}\")\n",
        "                imgs.append(fig_to_pil())\n",
        "                interps.append(llm_interpret_short(f\"Target class distribution: {target}\", f\"Counts per class\"))\n",
        "                num_preds = [c for c in num_cols if c != target]\n",
        "                if num_preds:\n",
        "                    df_drop = df[[target] + num_preds].dropna()\n",
        "                    if not df_drop.empty:\n",
        "                        X = df_drop[num_preds].fillna(0)\n",
        "                        y = pd.factorize(df_drop[target])[0]\n",
        "                        mi = mutual_info_classif(X, y, discrete_features=False)\n",
        "                        mi_series = pd.Series(mi, index=num_preds).sort_values(ascending=False)\n",
        "                        top = mi_series.head(3).index.tolist()\n",
        "                        for p in top:\n",
        "                            plt.figure(figsize=(5, 4))\n",
        "                            sns.boxplot(x=df[target].astype(str), y=df[p])\n",
        "                            plt.title(f\"{p} by {target}\")\n",
        "                            imgs.append(fig_to_pil())\n",
        "                            interps.append(llm_interpret_short(f\"{p} by {target}\", f\"Distribution of {p} across classes of {target}.\"))\n",
        "        except Exception:\n",
        "            # be resilient to plotting failures\n",
        "            pass\n",
        "\n",
        "    # General EDA if no target visuals produced\n",
        "    if not imgs:\n",
        "        try:\n",
        "            if len(num_cols) >= 3:\n",
        "                plt.figure(figsize=(6, 5))\n",
        "                corr = df[num_cols].corr()\n",
        "                sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
        "                plt.title(\"Correlation heatmap\")\n",
        "                imgs.append(fig_to_pil())\n",
        "                interps.append(llm_interpret_short(\"Correlation heatmap\", \"Pairwise correlations among numeric variables.\"))\n",
        "                for c in num_cols[:2]:\n",
        "                    plt.figure(figsize=(5, 3))\n",
        "                    sns.histplot(df[c].dropna(), kde=True)\n",
        "                    plt.title(f\"Distribution: {c}\")\n",
        "                    imgs.append(fig_to_pil())\n",
        "                    interps.append(llm_interpret_short(f\"Distribution: {c}\", f\"Histogram of {c}.\"))\n",
        "            elif num_cols and cat_cols:\n",
        "                plt.figure(figsize=(6, 4))\n",
        "                sns.boxplot(x=cat_cols[0], y=num_cols[0], data=df)\n",
        "                plt.title(f\"{num_cols[0]} by {cat_cols[0]}\")\n",
        "                imgs.append(fig_to_pil())\n",
        "                interps.append(llm_interpret_short(f\"{num_cols[0]} by {cat_cols[0]}\", \"Boxplots per category.\"))\n",
        "                plt.figure(figsize=(5, 3))\n",
        "                vc = df[cat_cols[0]].value_counts().head(10)\n",
        "                sns.barplot(x=vc.values, y=vc.index)\n",
        "                plt.title(f\"Counts: {cat_cols[0]}\")\n",
        "                imgs.append(fig_to_pil())\n",
        "                interps.append(llm_interpret_short(f\"Counts: {cat_cols[0]}\", \"Category frequency.\"))\n",
        "            elif cat_cols:\n",
        "                plt.figure(figsize=(5, 3))\n",
        "                vc = df[cat_cols[0]].value_counts().head(10)\n",
        "                sns.barplot(x=vc.values, y=vc.index)\n",
        "                plt.title(f\"Counts: {cat_cols[0]}\")\n",
        "                imgs.append(fig_to_pil())\n",
        "                interps.append(llm_interpret_short(f\"Counts: {cat_cols[0]}\", \"Category frequency.\"))\n",
        "            elif date_cols and num_cols:\n",
        "                d = date_cols[0]\n",
        "                df_sorted = df.sort_values(d)\n",
        "                plt.figure(figsize=(7, 3))\n",
        "                plt.plot(df_sorted[d], df_sorted[num_cols[0]])\n",
        "                plt.title(f\"Trend: {num_cols[0]} over {d}\")\n",
        "                imgs.append(fig_to_pil())\n",
        "                interps.append(llm_interpret_short(f\"Trend {num_cols[0]} over {d}\", \"Time trend line.\"))\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    if not imgs:\n",
        "        interps.append(\"No visuals generated â€” dataset may be empty or unsupported.\")\n",
        "    return imgs, interps"
      ],
      "metadata": {
        "id": "9UkxoZjuEqKb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- Quick modeling ----------\n",
        "def run_quick_regression(df, target):\n",
        "    res = {\"notes\": \"\", \"metrics\": {}, \"images\": [], \"interps\": []}\n",
        "    num_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
        "    preds = [c for c in num_cols if c != target]\n",
        "    if target not in df.columns or len(preds) == 0:\n",
        "        res[\"notes\"] = \"Not enough numeric predictors for regression.\"\n",
        "        return res\n",
        "    corr = df[[target] + preds].corr()[target].abs().drop(labels=[target], errors='ignore').sort_values(ascending=False)\n",
        "    top_preds = corr.head(3).index.tolist()\n",
        "    df_drop = df[[target] + top_preds].dropna()\n",
        "    if df_drop.shape[0] < 10:\n",
        "        res[\"notes\"] = \"Too few rows to run regression robustly.\"\n",
        "        return res\n",
        "    X = df_drop[top_preds]; y = df_drop[target]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
        "    model = LinearRegression().fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    r2 = r2_score(y_test, y_pred); mae = mean_absolute_error(y_test, y_pred)\n",
        "    res[\"metrics\"] = {\"r2\": r2, \"mae\": mae, \"n_train\": len(X_train), \"n_test\": len(X_test)}\n",
        "    try:\n",
        "        p = top_preds[0]\n",
        "        plt.figure(figsize=(5, 4))\n",
        "        sns.scatterplot(x=df_drop[p], y=df_drop[target])\n",
        "        plt.title(f\"{target} vs {p}\")\n",
        "        res[\"images\"].append(fig_to_pil())\n",
        "        res[\"interps\"].append(llm_interpret_short(f\"{target} vs {p}\", f\"Scatter used in regression.\"))\n",
        "    except Exception:\n",
        "        pass\n",
        "    return res\n",
        "\n",
        "\n",
        "def run_quick_classification(df, target):\n",
        "    res = {\"notes\": \"\", \"metrics\": {}, \"images\": [], \"interps\": []}\n",
        "    num_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
        "    preds = [c for c in num_cols if c != target]\n",
        "    if target not in df.columns:\n",
        "        res[\"notes\"] = \"Target not in dataframe.\"\n",
        "        return res\n",
        "    df_drop = df[[target] + preds].dropna()\n",
        "    if df_drop.shape[0] < 30 or len(preds) == 0:\n",
        "        res[\"notes\"] = \"Too few rows or predictors for classification demo.\"\n",
        "        return res\n",
        "    X = df_drop[preds]; y = pd.factorize(df_drop[target])[0]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
        "    model = RandomForestClassifier(n_estimators=50, random_state=0, max_depth=6).fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred); f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    res[\"metrics\"] = {\"accuracy\": acc, \"f1_weighted\": f1, \"n_train\": len(X_train), \"n_test\": len(X_test)}\n",
        "    try:\n",
        "        imps = pd.Series(model.feature_importances_, index=preds).sort_values(ascending=False).head(10)\n",
        "        plt.figure(figsize=(6, 4))\n",
        "        sns.barplot(x=imps.values, y=imps.index)\n",
        "        plt.title(\"Top feature importances\")\n",
        "        res[\"images\"].append(fig_to_pil())\n",
        "        res[\"interps\"].append(llm_interpret_short(\"Feature importances\", \"Relative importance of numeric predictors.\"))\n",
        "    except Exception:\n",
        "        pass\n",
        "    return res"
      ],
      "metadata": {
        "id": "GHjDsW_yEhYY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Handlers (fixed to refresh dropdown and clear previous outputs)\n",
        "def handle_upload(file):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "      - preview_text (str)\n",
        "      - dropdown update (gr.update)\n",
        "      - detection message (str)\n",
        "      - gallery clear (gr.update)\n",
        "      - interp_md clear (str)\n",
        "      - final_md clear (str)\n",
        "    The extra outputs ensure previous visuals/text are cleared when Detect Target is clicked again.\n",
        "    \"\"\"\n",
        "    df, err = load_file_to_df(file)\n",
        "    if err:\n",
        "        # Clear dropdown + gallery + texts to avoid stale references causing errors later\n",
        "        return (\n",
        "            f\"{err}\",\n",
        "            gr.update(choices=[], value=None, visible=False),\n",
        "            \"No data loaded.\",\n",
        "            gr.update(value=[]),  # clear gallery\n",
        "            \"\",  # interp_md\n",
        "            \"\"   # final_md\n",
        "        )\n",
        "\n",
        "    cand, reason = detect_target_column(df)\n",
        "    cols = [\"All\"] + list(df.columns)\n",
        "    msg = f\"Detected target: {cand} â€” {reason}\" if cand else \"No target automatically detected. Please select one.\"\n",
        "    preview_text = df.head(5).to_csv(index=False)\n",
        "\n",
        "    # Ensure dropdown refreshed (choices replaced) and value set to candidate if present else \"All\".\n",
        "    selected_val = cand if (cand in cols) else \"All\"\n",
        "    return (\n",
        "        preview_text,\n",
        "        gr.update(choices=cols, value=selected_val, visible=True),\n",
        "        msg,\n",
        "        gr.update(value=[]),  # clear gallery\n",
        "        \"\",  # clear interp_md\n",
        "        \"\"   # clear final_md\n",
        "    )"
      ],
      "metadata": {
        "id": "Usn_lHt_Eayc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_targeted_eda(file, selected_target, progress=gr.Progress()):\n",
        "    \"\"\"\n",
        "    Main runner. Returns (images, interp_md, final_md).\n",
        "    Works when selected_target is \"All\" or any column (keeps robust checks).\n",
        "    \"\"\"\n",
        "    progress(0, desc=\"Reading dataset...\")\n",
        "    df, err = load_file_to_df(file)\n",
        "    if err:\n",
        "        return None, \"File loading failed.\", \"\"\n",
        "    progress(0.25, desc=\"Selecting visuals...\")\n",
        "    # If \"All\" or no selection -> general EDA\n",
        "    if selected_target == \"All\" or selected_target is None:\n",
        "        imgs, interp_list = select_visuals_for_dataset(df, target=None)\n",
        "        progress(0.6, desc=\"Summarizing insights...\")\n",
        "        summary = llm_final_summary(df, \"General EDA\", \"All columns\", \"\\n\".join(interp_list[:8]))\n",
        "        md_text = \"\\n\\n\".join(f\"**Visual {i+1}:** {t}\" for i, t in enumerate(interp_list))\n",
        "        progress(1.0, desc=\"Done\")\n",
        "        return imgs, md_text, summary\n",
        "\n",
        "    # If selected_target exists, ensure it's in df\n",
        "    if selected_target not in df.columns:\n",
        "        # Refresh dropdown to current columns to prevent future errors\n",
        "        cols = [\"All\"] + list(df.columns)\n",
        "        # Return an informative message (interp_md) and keep final empty â€” also prompt UI to refresh dropdown value\n",
        "        return None, (\n",
        "            f\"Selected target '{selected_target}' not found in dataset. Dropdown refreshed â€” please select again.\"\n",
        "        ), \"\"\n",
        "\n",
        "    imgs, interp_list = select_visuals_for_dataset(df, target=selected_target)\n",
        "    # determine task type safely\n",
        "    try:\n",
        "        is_numeric = pd.api.types.is_numeric_dtype(df[selected_target])\n",
        "    except Exception:\n",
        "        is_numeric = False\n",
        "    task_type = \"Regression\" if is_numeric else \"Classification\"\n",
        "    progress(0.6, desc=f\"Running quick {task_type} demo...\")\n",
        "    model_res = run_quick_regression(df, selected_target) if task_type == \"Regression\" else run_quick_classification(df, selected_target)\n",
        "    brief_visual_interps = \"\\n\".join(interp_list[:8])\n",
        "    progress(0.9, desc=\"Generating final summary...\")\n",
        "    final_summary = llm_final_summary(df, task_type, selected_target, brief_visual_interps)\n",
        "    md_parts = [f\"**Visual {i+1}:** {t}\" for i, t in enumerate(interp_list)]\n",
        "    if model_res.get(\"metrics\"):\n",
        "        md_parts.append(\"\\n**Quick model metrics:**\")\n",
        "        md_parts += [f\"- {k}: {v}\" for k, v in model_res[\"metrics\"].items()]\n",
        "    if model_res.get(\"notes\"):\n",
        "        md_parts.append(f\"\\n**Notes:** {model_res['notes']}\")\n",
        "    progress(1.0, desc=\"Done\")\n",
        "    return imgs + model_res.get(\"images\", []), \"\\n\\n\".join(md_parts), final_summary"
      ],
      "metadata": {
        "id": "isdRgbhpESMY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- Gradio UI ----------\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"# Auto-EDA v4 â€” Target Detection & Task-aware Analytics\")\n",
        "    gr.Markdown(\"Hugging Face LLM: \" + (\"connected\" if client else \" disabled\"))\n",
        "\n",
        "    with gr.Row():\n",
        "        file_input = gr.File(label=\"Upload CSV / Excel\")\n",
        "        preview = gr.Textbox(label=\"CSV preview (first rows)\", interactive=False)\n",
        "\n",
        "    detect_btn = gr.Button(\"Detect Target\")\n",
        "    target_dropdown = gr.Dropdown(label=\"Select target column\", choices=[], visible=False)\n",
        "    detect_msg = gr.Markdown(label=\"Detection message\")\n",
        "    run_btn = gr.Button(\"Run Targeted Analysis\", variant=\"primary\")\n",
        "\n",
        "    gallery = gr.Gallery(label=\"Generated Visuals\", columns=2)\n",
        "    interp_md = gr.Markdown(label=\"Per-visual auto-interpretations\")\n",
        "    final_md = gr.Markdown(label=\"Final analytics summary\")\n",
        "\n",
        "    # ---------- Functions for interactivity ----------\n",
        "    def update_target_caption(selected_target):\n",
        "        \"\"\"Refresh caption text when user changes the detected target dropdown.\"\"\"\n",
        "        if selected_target == \"All\":\n",
        "            return \"General dataset analysis mode (All columns selected).\"\n",
        "        elif selected_target:\n",
        "            return f\"Target manually selected: **{selected_target}**\"\n",
        "        else:\n",
        "            return \"No target selected.\"\n",
        "\n",
        "    # Detect target + refresh dropdown + clear visuals each time file is uploaded or detection rerun\n",
        "    detect_btn.click(\n",
        "        fn=handle_upload,\n",
        "        inputs=[file_input],\n",
        "        outputs=[preview, target_dropdown, detect_msg, gallery, interp_md, final_md]\n",
        "    )\n",
        "\n",
        "    # ðŸ”„ When user changes target column manually, refresh caption text\n",
        "    target_dropdown.change(\n",
        "        fn=update_target_caption,\n",
        "        inputs=target_dropdown,\n",
        "        outputs=detect_msg\n",
        "    )\n",
        "\n",
        "    # Run analysis button â€” runs EDA, visuals, interpretation, and summary\n",
        "    run_btn.click(\n",
        "        fn=run_targeted_eda,\n",
        "        inputs=[file_input, target_dropdown],\n",
        "        outputs=[gallery, interp_md, final_md]\n",
        "    )\n",
        "\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "nZEHFHf3D_V0",
        "outputId": "e2a2ba24-234d-4df8-c0f2-59d19d390f40"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://0f16fe709da182a49b.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://0f16fe709da182a49b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}